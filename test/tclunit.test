# ---------------------------------------------------------------------------
#
# -- tclunit.test
#
# ---------------------------------------------------------------------------

package require tcltest 2.2

namespace import -force tcltest::*

package require tclunit

namespace eval tclunit::test {}

# first run as part of a test suite, i.e. with call to test_file_start

test init_for_tests-1.1 {resets variables and arrays} -body {
    tclunit::init_for_tests
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 0
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 0
tclunit::cto(result)       = 
tclunit::cto(skipped)      = 0
tclunit::cto(testName)     = 
tclunit::cto(totalfailed)  = 0
tclunit::cto(totalpassed)  = 0
tclunit::cto(totalskipped) = 0
}

test run_all_tests-1.1 {call do_run_tests with runAllTests script} -setup {
    rename tclunit::do_run_tests tclunit::test::do_run_tests
    proc tclunit::do_run_tests {args} {puts $args}
} -body {
    tclunit::run_all_tests [file dirname [info script]]
} -cleanup {
    rename tclunit::do_run_tests {}
    rename tclunit::test::do_run_tests tclunit::do_run_tests
} -match glob -output {{
	set ::env(TCLTEST_OPTIONS) {-verbose {body pass skip start error}}
	cd "*/test"
	package require tcltest
	tcltest::runAllTests
	exit
    }
}

test run_test_file-1.1 {call do_run_tests with testfile script} -setup {
    rename tclunit::do_run_tests tclunit::test::do_run_tests
    proc tclunit::do_run_tests {args} {puts $args}
} -body {
    tclunit::run_test_file [info script]
} -cleanup {
    rename tclunit::do_run_tests {}
    rename tclunit::test::do_run_tests tclunit::do_run_tests
} -match glob -output {{
	set ::env(TCLTEST_OPTIONS) {-verbose {body pass skip start error}}
	cd */test
	source "*/test/tclunit.test"
	exit
    }
}

test do_run_tests-1.1 {spawn new interp and remote start tests} -constraints {
    emptyTest
}

test capture_test_output-1.1 {read and process a line from the remote interp} -constraints {
    emptyTest
}

test test_file_start-1.1 {initialize a new test suite} -setup {
    tclunit::init_for_tests
} -body {
    tclunit::test_file_start test_file_start-1.1-filename
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 0
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 0
tclunit::cto(result)       = 
tclunit::cto(skipped)      = 0
tclunit::cto(testName)     = 
tclunit::cto(totalfailed)  = 0
tclunit::cto(totalpassed)  = 0
tclunit::cto(totalskipped) = 0
}

test test_skipped-1.1 {count a skipped test} -body {
    tclunit::test_skipped "++++ test_skipped-1.1 SKIPPED: emptyTest"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 0
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 0
tclunit::cto(result)       = 
tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = 
tclunit::cto(totalfailed)  = 0
tclunit::cto(totalpassed)  = 0
tclunit::cto(totalskipped) = 1
}

test test_started-1.1 {name of just started test} -body {
    tclunit::test_started "---- test_started-1.1 start"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 0
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 0
tclunit::cto(result)       = 
tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_started-1.1
tclunit::cto(totalfailed)  = 0
tclunit::cto(totalpassed)  = 0
tclunit::cto(totalskipped) = 1
}

test test_passed-1.1 {count passed test} -body {
    tclunit::test_passed "++++ test_started-1.1 PASSED"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 0
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = 
tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_started-1.1
tclunit::cto(totalfailed)  = 0
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed-1.1 {count failure and mark capturing start} -body {
    tclunit::test_started "---- test_failed-1.1 start"
    tclunit::test_failed "==== test_failed-1.1 count failure and mark capturing start FAILED"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-1.1 {capture remaining failure output} -body {
    tclunit::test_failed_continue "==== Contents of test case:"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-1.2 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue ""
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:


tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-1.3 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "    return foo"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-1.4 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue ""
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo


tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-1.5 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "---- Result was:"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-1.6 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "foo"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:
foo

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-1.7 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "---- Result should have been (exact matching):"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:
foo
---- Result should have been (exact matching):

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-1.8 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue ""
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:
foo
---- Result should have been (exact matching):


tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-1.9 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "==== test_failed-1.1 FAILED"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = test_file_start-1.1-filename
tclunit::cto(filenames)    = test_file_start-1.1-filename
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:
foo
---- Result should have been (exact matching):

==== test_failed-1.1 FAILED

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test incr_test_counter-1.1 {increment given counter and update status} -constraints {
    emptyTest
} -body {
    # implicitely tested above for the various counters
}

test run_tests-1.1 {start tests according to configuration and report results} -constraints {
    emptyTest
}

test stop_tests-1.1 {stop testing immediately} -constraints {
    emptyTest
}

# second run as single test file, i.e. without call to test_file_start

test init_for_tests-2.1 {resets variables and arrays} -body {
    tclunit::init_for_tests
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 0
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 0
tclunit::cto(result)       = 
tclunit::cto(skipped)      = 0
tclunit::cto(testName)     = 
tclunit::cto(totalfailed)  = 0
tclunit::cto(totalpassed)  = 0
tclunit::cto(totalskipped) = 0
}

test test_skipped-2.1 {count a skipped test} -body {
    tclunit::test_skipped "++++ test_skipped-1.1 SKIPPED: emptyTest"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 0
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 0
tclunit::cto(result)       = 
tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = 
tclunit::cto(totalfailed)  = 0
tclunit::cto(totalpassed)  = 0
tclunit::cto(totalskipped) = 1
}

test test_started-2.1 {name of just started test} -body {
    tclunit::test_started "---- test_started-1.1 start"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 0
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 0
tclunit::cto(result)       = 
tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_started-1.1
tclunit::cto(totalfailed)  = 0
tclunit::cto(totalpassed)  = 0
tclunit::cto(totalskipped) = 1
}

test test_passed-2.1 {count passed test} -body {
    tclunit::test_passed "++++ test_started-1.1 PASSED"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 0
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = 
tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_started-1.1
tclunit::cto(totalfailed)  = 0
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed-2.1 {count failure and mark capturing start} -body {
    tclunit::test_started "---- test_failed-1.1 start"
    tclunit::test_failed "==== test_failed-1.1 count failure and mark capturing start FAILED"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-2.1 {capture remaining failure output} -body {
    tclunit::test_failed_continue "==== Contents of test case:"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-2.2 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue ""
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:


tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-2.3 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "    return foo"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-2.4 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue ""
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo


tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-2.5 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "---- Result was:"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-2.6 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "foo"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:
foo

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-2.7 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "---- Result should have been (exact matching):"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:
foo
---- Result should have been (exact matching):

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-2.8 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue ""
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 1
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:
foo
---- Result should have been (exact matching):


tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

test test_failed_continue-2.9 {capture remaining failure output, cont'd} -body {
    tclunit::test_failed_continue "==== test_failed-1.1 FAILED"
    parray tclunit::cto
} -output {tclunit::cto(capturing)    = 0
tclunit::cto(failed)       = 1
tclunit::cto(filename)     = 
tclunit::cto(passed)       = 1
tclunit::cto(result)       = ==== test_failed-1.1 count failure and mark capturing start FAILED
==== Contents of test case:

    return foo

---- Result was:
foo
---- Result should have been (exact matching):

==== test_failed-1.1 FAILED

tclunit::cto(skipped)      = 1
tclunit::cto(testName)     = test_failed-1.1
tclunit::cto(totalfailed)  = 1
tclunit::cto(totalpassed)  = 1
tclunit::cto(totalskipped) = 1
}

# out of sequence tests

test configure-1.1 {complete configuration introspection} -body {
    tclunit::configure
} -match glob -result {{event error noop}\
 {event failed noop}\
 {event init noop}\
 {event passed noop}\
 {event property noop}\
 {event skipped noop}\
 {event start noop}\
 {event status noop}\
 {event suite noop}\
 {event total noop}\
 {interp *}\
 {tcltest {-verbose {body pass skip start error}}}}

test configure-1.2 {configuration sub commands} -body {
    tclunit::configure help
} -returnCodes error -result {unknown command help, must be event, interp, tcltest or reset}

test configure-2.1 {event tag list retrieval} -body {
    tclunit::configure event help
} -returnCodes error -result {unknown event help, must be one of: error, failed, init, passed, property, skipped, start, status, suite, total}

test configure-2.2 {event tag value query} -body {
    tclunit::configure event init
} -result {{event init noop}}

test configure-2.3 {event tag configuration and subsequent usage} -setup {
    proc tclunit::test::check4Call {args} {
	variable configure14Check
	set configure14Check $args
    }
} -body {
    namespace eval tclunit::test {
	tclunit::configure event init [namespace code [list check4Call called]]
    }
    tclunit::init_for_tests
    set tclunit::test::configure14Check
} -cleanup {
    unset tclunit::test::configure14Check
    rename tclunit::test::check4Call {}
} -result {called}

test configure-3.1 {default interp is this one} -body {
    join [tclunit::configure interp] " "
} -result [list interp [info nameofexecutable]]

test configure-3.2 {configure other interp to use} -setup {
    set configure32interp $tclunit::rt(interp)
} -body {
    list [tclunit::configure interp /usr/bin/sh] [set tclunit::rt(interp)]
} -cleanup {
    set tclunit::rt(interp) $configure32interp
    unset configure32interp
} -result {{} /usr/bin/sh}

test configure-4.1 {default tcltest config is min required by tclunit} -body {
    join [tclunit::configure tcltest] " "
} -result {tcltest {-verbose {body pass skip start error}}}

test configure-4.2 {tcltest config drops -verbose, -outfile and -errfile} -body {
    tclunit::configure tcltest {-file tcltest.test -outfile tcltest.out -errfile tcltest.err -verbose pbsetl}
    join [tclunit::configure tcltest] " "
} -result {tcltest {-file tcltest.test -verbose {body pass skip start error}}}

test configure-5.1 {reset of runtime configuration} -body {
    list [tclunit::configure reset] [tclunit::configure]
} -match glob -result {{}\
 {{event error noop}\
  {event failed noop}\
  {event init noop}\
  {event passed noop}\
  {event property noop}\
  {event skipped noop}\
  {event start noop}\
  {event status noop}\
  {event suite noop}\
  {event total noop}\
  {interp *}\
  {tcltest {-verbose {body pass skip start error}}}}}

test read_testlog-1.1 {read a test log} -setup {
    rename tclunit::noop tclunit::test::noop
    proc tclunit::noop {args} {puts "[lindex [info level -1] 0]:[join $args "|"]"}
} -body {
    tclunit::run_tests [file join [file dirname [info script]] tclunit-test.log]
} -cleanup {
    rename tclunit::noop {}
    rename tclunit::test::noop tclunit::noop
} -match glob -output {init_for_tests:
test_properties:Tests running in interp|*
test_properties:Tests located in|*/test
test_properties:Tests running in|*
test_properties:Temporary files stored in|*
test_properties:Running tests that match|\*
test_properties:Skipping test files that match|l\.\*\.test
test_properties:Only running test files that match|\*\.test
test_file_start:tclunit.test
test_started:tclunit.test|init_for_tests-1.1
incr_test_counter:tclunit.test|1|0|0
test_passed:tclunit.test|init_for_tests-1.1
test_started:tclunit.test|run_all_tests-1.1
incr_test_counter:tclunit.test|2|0|0
test_passed:tclunit.test|run_all_tests-1.1
test_started:tclunit.test|run_test_file-1.1
incr_test_counter:tclunit.test|3|0|0
test_passed:tclunit.test|run_test_file-1.1
incr_test_counter:tclunit.test|3|1|0
test_skipped:tclunit.test|do_run_tests-1.1|emptyTest
incr_test_counter:tclunit.test|3|2|0
test_skipped:tclunit.test|capture_test_output-1.1|emptyTest
test_started:tclunit.test|test_file_start-1.1
incr_test_counter:tclunit.test|4|2|0
test_passed:tclunit.test|test_file_start-1.1
test_started:tclunit.test|test_skipped-1.1
incr_test_counter:tclunit.test|5|2|0
test_passed:tclunit.test|test_skipped-1.1
test_started:tclunit.test|test_started-1.1
incr_test_counter:tclunit.test|6|2|0
test_passed:tclunit.test|test_started-1.1
test_started:tclunit.test|test_passed-1.1
incr_test_counter:tclunit.test|7|2|0
test_passed:tclunit.test|test_passed-1.1
test_started:tclunit.test|test_failed-1.1
incr_test_counter:tclunit.test|8|2|0
test_passed:tclunit.test|test_failed-1.1
test_started:tclunit.test|test_failed_continue-1.1
incr_test_counter:tclunit.test|9|2|0
test_passed:tclunit.test|test_failed_continue-1.1
test_started:tclunit.test|test_failed_continue-1.2
incr_test_counter:tclunit.test|10|2|0
test_passed:tclunit.test|test_failed_continue-1.2
test_started:tclunit.test|test_failed_continue-1.3
incr_test_counter:tclunit.test|11|2|0
test_passed:tclunit.test|test_failed_continue-1.3
test_started:tclunit.test|test_failed_continue-1.4
incr_test_counter:tclunit.test|12|2|0
test_passed:tclunit.test|test_failed_continue-1.4
test_started:tclunit.test|test_failed_continue-1.5
incr_test_counter:tclunit.test|13|2|0
test_passed:tclunit.test|test_failed_continue-1.5
test_started:tclunit.test|test_failed_continue-1.6
incr_test_counter:tclunit.test|14|2|0
test_passed:tclunit.test|test_failed_continue-1.6
test_started:tclunit.test|test_failed_continue-1.7
incr_test_counter:tclunit.test|15|2|0
test_passed:tclunit.test|test_failed_continue-1.7
test_started:tclunit.test|test_failed_continue-1.8
incr_test_counter:tclunit.test|16|2|0
test_passed:tclunit.test|test_failed_continue-1.8
test_started:tclunit.test|test_failed_continue-1.9
incr_test_counter:tclunit.test|17|2|0
test_passed:tclunit.test|test_failed_continue-1.9
incr_test_counter:tclunit.test|17|3|0
test_skipped:tclunit.test|incr_test_counter-1.1|emptyTest
incr_test_counter:tclunit.test|17|4|0
test_skipped:tclunit.test|run_tests-1.1|emptyTest
incr_test_counter:tclunit.test|17|5|0
test_skipped:tclunit.test|stop_tests-1.1|emptyTest
test_started:tclunit.test|init_for_tests-2.1
incr_test_counter:tclunit.test|18|5|0
test_passed:tclunit.test|init_for_tests-2.1
test_started:tclunit.test|test_skipped-2.1
incr_test_counter:tclunit.test|19|5|0
test_passed:tclunit.test|test_skipped-2.1
test_started:tclunit.test|test_started-2.1
incr_test_counter:tclunit.test|20|5|0
test_passed:tclunit.test|test_started-2.1
test_started:tclunit.test|test_passed-2.1
incr_test_counter:tclunit.test|21|5|0
test_passed:tclunit.test|test_passed-2.1
test_started:tclunit.test|test_failed-2.1
incr_test_counter:tclunit.test|22|5|0
test_passed:tclunit.test|test_failed-2.1
test_started:tclunit.test|test_failed_continue-2.1
incr_test_counter:tclunit.test|23|5|0
test_passed:tclunit.test|test_failed_continue-2.1
test_started:tclunit.test|test_failed_continue-2.2
incr_test_counter:tclunit.test|24|5|0
test_passed:tclunit.test|test_failed_continue-2.2
test_started:tclunit.test|test_failed_continue-2.3
incr_test_counter:tclunit.test|25|5|0
test_passed:tclunit.test|test_failed_continue-2.3
test_started:tclunit.test|test_failed_continue-2.4
incr_test_counter:tclunit.test|26|5|0
test_passed:tclunit.test|test_failed_continue-2.4
test_started:tclunit.test|test_failed_continue-2.5
incr_test_counter:tclunit.test|27|5|0
test_passed:tclunit.test|test_failed_continue-2.5
test_started:tclunit.test|test_failed_continue-2.6
incr_test_counter:tclunit.test|28|5|0
test_passed:tclunit.test|test_failed_continue-2.6
test_started:tclunit.test|test_failed_continue-2.7
incr_test_counter:tclunit.test|29|5|0
test_passed:tclunit.test|test_failed_continue-2.7
test_started:tclunit.test|test_failed_continue-2.8
incr_test_counter:tclunit.test|30|5|0
test_passed:tclunit.test|test_failed_continue-2.8
test_started:tclunit.test|test_failed_continue-2.9
incr_test_counter:tclunit.test|31|5|0
test_passed:tclunit.test|test_failed_continue-2.9
test_started:tclunit.test|configure-1.1
incr_test_counter:tclunit.test|32|5|0
test_passed:tclunit.test|configure-1.1
test_started:tclunit.test|configure-2.1
incr_test_counter:tclunit.test|33|5|0
test_passed:tclunit.test|configure-2.1
test_started:tclunit.test|configure-2.2
incr_test_counter:tclunit.test|34|5|0
test_passed:tclunit.test|configure-2.2
test_started:tclunit.test|configure-2.3
incr_test_counter:tclunit.test|35|5|0
test_passed:tclunit.test|configure-2.3
test_started:tclunit.test|configure-3.1
incr_test_counter:tclunit.test|36|5|0
test_passed:tclunit.test|configure-3.1
test_started:tclunit.test|configure-3.2
incr_test_counter:tclunit.test|37|5|0
test_passed:tclunit.test|configure-3.2
test_started:tclunit.test|configure-4.1
incr_test_counter:tclunit.test|38|5|0
test_passed:tclunit.test|configure-4.1
test_started:tclunit.test|configure-4.2
incr_test_counter:tclunit.test|39|5|0
test_passed:tclunit.test|configure-4.2
test_file_start:tests4tclunit.test
test_started:tests4tclunit.test|success-1.1
incr_test_counter:tests4tclunit.test|1|0|0
test_passed:tests4tclunit.test|success-1.1
test_started:tests4tclunit.test|failure-1.1
incr_test_counter:tests4tclunit.test|1|0|1
test_failed_continue:tests4tclunit.test|failure-1.1|==== failure-1.1 Failing test FAILED
==== Contents of test case:

    expr 1

---- Result was:
1
---- Result should have been (exact matching):
2
==== failure-1.1 FAILED

incr_test_counter:tests4tclunit.test|1|1|1
test_skipped:tests4tclunit.test|skip-1.1|emptyTest
tclunit::run_tests:40|6|1|2000
}

# test suite cleanup
tcltest::cleanupTests 0
